{"meta":{"title":"sun-moon-star-star","subtitle":"","description":"","author":"sun-moon-star-star","url":"https://sun-moon-star-star.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-02-10T03:10:00.754Z","updated":"2021-02-10T03:10:00.753Z","comments":false,"path":"/404.html","permalink":"https://sun-moon-star-star.github.io/404.html","excerpt":"","text":""},{"title":"Rongming-lu(鲁荣明)","date":"2021-02-19T09:11:43.000Z","updated":"2021-02-19T09:11:43.000Z","comments":false,"path":"about/index.html","permalink":"https://sun-moon-star-star.github.io/about/index.html","excerpt":"","text":"教育信息 2016.09-2020.06 湖南中医药大学 计算机科学与技术 本科综合测评1/59 湖南省优秀毕业生 ACM-ICPC银奖(2018·Beijing) 技能 数据结构与算法: Skiplist、B+tree、Sort、DP、String分布式一致性算法: 2pc、3pc、Raft、Paxos、Gossip中间件: Mysql、Redis、Kafka、Zookeeper服务治理: 服务发现、心跳保活、限流熔断、认证鉴权、故障转移、负载均衡、分布式配置中心、数据压缩版本管理工具: GitGolang: goroutine调度器、常用并发原语、GC回收机制、Map底层实现、slice动态扩容、channel通信MySQL: 常见存储引擎、SQL执行流程、MySQL事务及其隔离级别、MySQL锁、索引设计、MySQL调优Redis: 常用数据结构、Redis持久化、哨兵机制、Redis数据淘汰策略、缓存雪崩、缓存穿透、缓存击穿解决方案Kafka: 生产者消息分区机制、消费者组位移管理、Rebalance、Kafka副本同步机制、Kafka控制器 项目经历 基于Paxos协议的Key/Value存储系统 基于Golang语言并发和rpc调用来模拟多节点的Key/Value存储系统使用paxos协议实现日志同步，以保证统一的节点视图及数据副本间的一致性 流量录制和回放工具 录制线上真实请求流量进行回放测试，适合项目重构、回归测试回放的时候匹配Mock下游调用，解决维护测试环境成本高的问题"},{"title":"书单","date":"2021-02-10T03:10:00.861Z","updated":"2021-02-10T03:10:00.861Z","comments":false,"path":"books/index.html","permalink":"https://sun-moon-star-star.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-02-10T03:10:00.910Z","updated":"2021-02-10T03:10:00.910Z","comments":false,"path":"categories/index.html","permalink":"https://sun-moon-star-star.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-02-10T03:10:00.954Z","updated":"2021-02-10T03:10:00.953Z","comments":true,"path":"links/index.html","permalink":"https://sun-moon-star-star.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-02-10T03:10:01.043Z","updated":"2021-02-10T03:10:01.043Z","comments":false,"path":"repository/index.html","permalink":"https://sun-moon-star-star.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-02-10T03:10:01.002Z","updated":"2021-02-10T03:10:01.002Z","comments":false,"path":"tags/index.html","permalink":"https://sun-moon-star-star.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"sysmon","slug":"sysmon","date":"2021-03-16T03:20:21.000Z","updated":"2021-03-16T04:00:13.127Z","comments":true,"path":"2021/03/16/sysmon/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/03/16/sysmon/","excerpt":"","text":"sysmon sysmon 执行一个无限循环，一开始每次循环休眠 20us，之后（1 ms 后）每次休眠时间倍增，最终每一轮都会休眠 10ms。 sysmon 中会进行 netpool（获取 fd 事件）、retake（抢占）、forcegc（按时间强制执行 gc），scavenge heap（释放自由列表中多余的项减少内存占用）等处理。 和调度相关的，我们只关心 retake 函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func retake(now int64) uint32 &#123; n := 0 // 遍历所有的 p for i := int32(0); i &lt; gomaxprocs; i++ &#123; _p_ := allp[i] if _p_ == nil &#123; continue &#125; // 用于 sysmon 线程记录被监控 p 的系统调用时间和运行时间 pd := &amp;_p_.sysmontick // p 的状态 s := _p_.status if s == _Psyscall &#123; // P 处于系统调用之中，需要检查是否需要抢占 // Retake P from syscall if it&#x27;s there for more than 1 sysmon tick (at least 20us). // _p_.syscalltick 用于记录系统调用的次数，在完成系统调用之后加 1 t := int64(_p_.syscalltick) if int64(pd.syscalltick) != t &#123; // pd.syscalltick != _p_.syscalltick，说明已经不是上次观察到的系统调用了， // 而是另外一次系统调用，所以需要重新记录 tick 和 when 值 pd.syscalltick = uint32(t) pd.syscallwhen = now continue &#125; // 只要满足下面三个条件中的任意一个，则抢占该 p，否则不抢占 // 1. p 的运行队列里面有等待运行的 goroutine // 2. 没有无所事事的 p // 3. 从上一次监控线程观察到 p 对应的 m 处于系统调用之中到现在已经超过 10 毫秒 if runqempty(_p_) &amp;&amp; atomic.Load(&amp;sched.nmspinning)+atomic.Load(&amp;sched.npidle) &gt; 0 &amp;&amp; pd.syscallwhen+10*1000*1000 &gt; now &#123; continue &#125; incidlelocked(-1) if atomic.Cas(&amp;_p_.status, s, _Pidle) &#123; // …………………… n++ _p_.syscalltick++ // 寻找一新的 m 接管 p handoffp(_p_) &#125; incidlelocked(1) &#125; else if s == _Prunning &#123; // P 处于运行状态，检查是否运行得太久了 // Preempt G if it&#x27;s running for too long. // 每发生一次调度，调度器 ++ 该值 t := int64(_p_.schedtick) if int64(pd.schedtick) != t &#123; pd.schedtick = uint32(t) pd.schedwhen = now continue &#125; //pd.schedtick == t 说明(pd.schedwhen ～ now)这段时间未发生过调度 // 这段时间是同一个goroutine一直在运行，检查是否连续运行超过了 10 毫秒 if pd.schedwhen+forcePreemptNS &gt; now &#123; continue &#125; // 连续运行超过 10 毫秒了，发起抢占请求 preemptone(_p_) &#125; &#125; return uint32(n)&#125; 从代码来看，主要会对处于 _Psyscall 和 _Prunning 状态的 p 进行抢占。 抢占进行系统调用的 P当 P 处于 _Psyscall 状态时，表明对应的 goroutine 正在进行系统调用。如果抢占 p，需要满足几个条件： p 的本地运行队列里面有等待运行的 goroutine。这时 p 绑定的 g 正在进行系统调用，无法去执行其他的 g，因此需要接管 p 来执行其他的 g。 没有“无所事事”的 p。sched.nmspinning 和 sched.npidle 都为 0，这就意味着没有“找工作”的 m，也没有空闲的 p，大家都在“忙”，可能有很多工作要做。因此要抢占当前的 p，让它来承担一部分工作。 从上一次监控线程观察到 p 对应的 m 处于系统调用之中到现在已经超过 10 毫秒。这说明系统调用所花费的时间较长，需要对其进行抢占，以此来使得 retake 函数返回值不为 0，这样，会保持 sysmon 线程 20 us 的检查周期，提高 sysmon 监控的实时性。 注意，原代码是用的三个与条件，三者都要满足才会执行下面的 continue，也就是不进行抢占。因此要想进行抢占的话，只需要三个条件有一个不满足就行了。于是就有了上述三种情况。 确定要抢占当前 p 后，先使用原子操作将 p 的状态修改为 _Pidle，最后调用 handoffp 进行抢占。 1234567891011121314151617181920212223242526func handoffp(_p_ *p) &#123; // 如果 p 本地有工作或者全局有工作，需要绑定一个 m if !runqempty(_p_) || sched.runqsize != 0 &#123; startm(_p_, false) return &#125; // …………………… // 所有其它 p 都在运行 goroutine，说明系统比较忙，需要启动 m if atomic.Load(&amp;sched.nmspinning)+atomic.Load(&amp;sched.npidle) == 0 &amp;&amp; atomic.Cas(&amp;sched.nmspinning, 0, 1) &#123; // TODO: fast atomic // p 没有本地工作，启动一个自旋 m 来找工作 startm(_p_, true) return &#125; lock(&amp;sched.lock) // …………………… // 全局队列有工作 if sched.runqsize != 0 &#123; unlock(&amp;sched.lock) startm(_p_, false) return &#125; // …………………… // 没有工作要处理，把 p 放入全局空闲队列 pidleput(_p_) unlock(&amp;sched.lock)&#125; handoffp 再次进行场景判断，以调用 startm 启动一个工作线程来绑定 p，使得整体工作继续推进。 当 p 的本地运行队列或全局运行队列里面有待运行的 goroutine，说明还有很多工作要做，调用 startm(p, false) 启动一个 m 来结合 p，继续工作。 当除了当前的 p 外，其他所有的 p 都在运行 goroutine，说明天下太平，每个人都有自己的事做，唯独自己没有。为了全局更快地完成工作，需要启动一个 m，且要使得 m 处于自旋状态，和 p 结合之后，尽快找到工作。 最后，如果实在没有工作要处理，就将 p 放入全局空闲队列里。 我们接着来看 startm 函数都做了些什么： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// runtime/proc.go//// 调用 m 来绑定 p，如果没有 m，那就新建一个// 如果 p 为空，那就尝试获取一个处于空闲状态的 p，如果找到 p，那就什么都不做func startm(_p_ *p, spinning bool) &#123; lock(&amp;sched.lock) if _p_ == nil &#123; // 没有指定 p 则需要从全局空闲队列中获取一个 p _p_ = pidleget() if _p_ == nil &#123; unlock(&amp;sched.lock) if spinning &#123; // 如果找到 p，放弃。还原全局处于自旋状态的 m 的数量 if int32(atomic.Xadd(&amp;sched.nmspinning, -1)) &lt; 0 &#123; throw(&quot;startm: negative nmspinning&quot;) &#125; &#125; // 没有空闲的 p，直接返回 return &#125; &#125; // 从 m 空闲队列中获取正处于睡眠之中的工作线程， // 所有处于睡眠状态的 m 都在此队列中 mp := mget() unlock(&amp;sched.lock) if mp == nil &#123; // 如果没有找到 m var fn func() if spinning &#123; // The caller incremented nmspinning, so set m.spinning in the new M. fn = mspinning &#125; // 创建新的工作线程 newm(fn, _p_) return &#125; if mp.spinning &#123; throw(&quot;startm: m is spinning&quot;) &#125; if mp.nextp != 0 &#123; throw(&quot;startm: m has p&quot;) &#125; if spinning &amp;&amp; !runqempty(_p_) &#123; throw(&quot;startm: p has runnable gs&quot;) &#125; // The caller incremented nmspinning, so set m.spinning in the new M. mp.spinning = spinning // 设置 m 马上要结合的 p mp.nextp.set(_p_) // 唤醒 m notewakeup(&amp;mp.park)&#125; 首先处理 p 为空的情况，直接从全局空闲 p 队列里找，如果没找到，则直接返回。如果设置了 spinning 为 true 的话，还需要还原全局的处于自旋状态的 m 的数值：&amp;sched.nmspinning 。 搞定了 p，接下来看 m。先调用 mget 函数从全局空闲的 m 队列里获取一个 m，如果没找到 m，则要调用 newm 新创建一个 m，并且如果设置了 spinning 为 true 的话，先要设置好 mstartfn： 1234func mspinning()&#123;// startm&#x27;s caller incremented nmspinning. Set the new M&#x27;s spinning. getg().m.spinning =true&#125; 这样，启动 m 后，在 mstart1 函数里，进入 schedule 循环前，执行 mstartfn 函数，使得 m 处于自旋状态。 接下来是正常情况下（找到了 p 和 m）的处理： 12345mp.spinning = spinning// 设置 m 马上要结合的 pmp.nextp.set(_p_)// 唤醒 mnotewakeup(&amp;mp.park) 设置 nextp 为找到的 p，调用 notewakeup 唤醒 m。之前我们讲 findrunnable 函数的时候，对于最后没有找到工作的 m，我们调用 notesleep(&amp;g.m.park)，使得 m 进入睡眠状态。现在终于有工作了，需要老将出山，将其唤醒： 1234567891011// src/runtime/lock_futex.gofunc notewakeup(n *note) &#123; // 设置 n.key = 1, 被唤醒的线程通过查看该值是否等于 1 // 来确定是被其它线程唤醒还是意外从睡眠中苏醒 old := atomic.Xchg(key32(&amp;n.key), 1) if old != 0 &#123; print(&quot;notewakeup - double wakeup (&quot;, old, &quot;)\\n&quot;) throw(&quot;notewakeup - double wakeup&quot;) &#125; futexwakeup(key32(&amp;n.key), 1)&#125; notewakeup 函数首先使用 atomic.Xchg 设置 note.key 值为 1，这是为了使被唤醒的线程可以通过查看该值是否等于 1 来确定是被其它线程唤醒还是意外从睡眠中苏醒了过来。如果该值为 1 则表示是被唤醒的，可以继续工作，但如果该值为 0 则表示是意外苏醒，需要再次进入睡眠。 调用 futexwakeup 来唤醒工作线程，它和 futexsleep 是相对的。 12345678func futexwakeup(addr *uint32, cnt uint32) &#123; // 调用 futex 函数唤醒工作线程 ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE, cnt, nil, nil, 0) if ret &gt;= 0 &#123; return &#125; // ……………………&#125; futex 由汇编语言实现，前面已经分析过，这里就不重复了。主要内容就是先准备好参数，然后进行系统调用，由内核唤醒线程。 内核在完成唤醒工作之后当前工作线程从内核返回到 futex 函数继续执行 SYSCALL 指令之后的代码并按函数调用链原路返回，继续执行其它代码。而被唤醒的工作线程则由内核负责在适当的时候调度到 CPU 上运行。 抢占长时间运行的 P我们知道，Go scheduler 采用的是一种称为协作式的抢占式调度，就是说并不强制调度，大家保持协作关系，互相信任。对于长时间运行的 P，或者说绑定在 P 上的长时间运行的 goroutine，sysmon 会检测到这种情况，然后设置一些标志，表示 goroutine 自己让出 CPU 的执行权，给其他 goroutine 一些机会。 接下来我们就来分析当 P 处于 _Prunning 状态的情况。sysmon 扫描每个 p 时，都会记录下当前调度器调度的次数和当前时间，数据记录在结构体： 123456type sysmontick struct&#123; schedtick uint32 schedwhen int64 syscalltick uint32 syscallwhen int64&#125; 前面两个字段记录调度器调度的次数和时间，后面两个字段记录系统调用的次数和时间。 在下一次扫描时，对比 sysmon 记录下的 p 的调度次数和时间，与当前 p 自己记录下的调度次数和时间对比，如果一致。说明 P 在这一段时间内一直在运行同一个 goroutine。那就来计算一下运行时间是否太长了。 如果发现运行时间超过了 10 ms，则要调用 preemptone(p) 发起抢占的请求： 123456789101112131415161718func preemptone(_p_ *p) bool &#123; mp := _p_.m.ptr() if mp == nil || mp == getg().m &#123; returnfalse &#125; // 被抢占的 goroutine gp := mp.curg if gp == nil || gp == mp.g0 &#123; returnfalse &#125; // 设置抢占标志 gp.preempt = true // 在 goroutine 内部的每次调用都会比较栈顶指针和 g.stackguard0， // 来判断是否发生了栈溢出。stackPreempt 非常大的一个数，比任何栈都大 // stackPreempt = 0xfffffade gp.stackguard0 = stackPreempt returntrue&#125; 基本上只是将 stackguard0 设置了一个很大的值，而检查 stackguard0 的地方在函数调用前的一段汇编代码里进行。 举一个简单的例子： 1234567package mainimport&quot;fmt&quot;func main()&#123; fmt.Println(&quot;hello qcrao.com!&quot;)&#125; 执行命令： 1go tool compile -S main.go 得到汇编代码： 1234567891011121314151617181920212223242526272829&quot;&quot;.main STEXT size&#x3D;120 args&#x3D;0x0 locals&#x3D;0x480x000000000(test26.go:5) TEXT &quot;&quot;.main(SB), $72-00x000000000(test26.go:5) MOVQ (TLS), CX0x000900009(test26.go:5) CMPQ SP,16(CX)0x000d00013(test26.go:5) JLS 1130x000f00015(test26.go:5) SUBQ $72, SP0x001300019(test26.go:5) MOVQ BP,64(SP)0x001800024(test26.go:5) LEAQ 64(SP), BP0x001d00029(test26.go:5) FUNCDATA $0, gclocals·69c1753bd5f81501d95132d08af04464(SB)0x001d00029(test26.go:5) FUNCDATA $1, gclocals·e226d4ae4a7cad8835311c6a4683c14f(SB)0x001d00029(test26.go:6) MOVQ $0,&quot;&quot;..autotmp_0+48(SP)0x002600038(test26.go:6) MOVQ $0,&quot;&quot;..autotmp_0+56(SP)0x002f00047(test26.go:6) LEAQ type.string(SB), AX0x003600054(test26.go:6) MOVQ AX,&quot;&quot;..autotmp_0+48(SP)0x003b00059(test26.go:6) LEAQ &quot;&quot;.statictmp_0(SB), AX0x004200066(test26.go:6) MOVQ AX,&quot;&quot;..autotmp_0+56(SP)0x004700071(test26.go:6) LEAQ &quot;&quot;..autotmp_0+48(SP), AX0x004c00076(test26.go:6) MOVQ AX,(SP)0x005000080(test26.go:6) MOVQ $1,8(SP)0x005900089(test26.go:6) MOVQ $1,16(SP)0x006200098(test26.go:6) PCDATA $0, $10x006200098(test26.go:6) CALL fmt.Println(SB)0x006700103(test26.go:7) MOVQ 64(SP), BP0x006c00108(test26.go:7) ADDQ $72, SP0x007000112(test26.go:7) RET0x007100113(test26.go:7) NOP0x007100113(test26.go:5) PCDATA $0, $-10x007100113(test26.go:5) CALL runtime.morestack_noctxt(SB)0x007600118(test26.go:5) JMP 0 10x000000000(test26.go:5) MOVQ (TLS), CX 将本地存储 tls 保存到 CX 寄存器中，（TLS）表示它所关联的 g，这里就是前面所讲到的 main gouroutine。 10x000900009(test26.go:5) CMPQ SP,16(CX) 比较 SP 寄存器（代表当前 main goroutine 的栈顶寄存器）和 16(CX)，我们看下 g 结构体： 1234567891011type g struct&#123;// goroutine 使用的栈 stack stack // offset known to runtime/cgo// 用于栈的扩张和收缩检查 stackguard0 uintptr // offset known to liblink// ……………………&#125;type stack struct&#123; lo uintptr hi uintptr&#125; 共 16 字节。而 16(CX) 表示 g 对象的第 16 个字节，跳过了 g 的第一个字段，也就是 g.stackguard0 字段。 如果 SP 小于 g.stackguard0，这是必然的，因为前面已经把 g.stackguard0 设置成了一个非常大的值，因此跳转到了 113 行。 12340x007100113(test26.go:7) NOP0x007100113(test26.go:5) PCDATA $0, $-10x007100113(test26.go:5) CALL runtime.morestack_noctxt(SB)0x007600118(test26.go:5) JMP 0 调用 runtime.morestack_noctxt 函数： 1234&#x2F;&#x2F; src&#x2F;runtime&#x2F;asm_amd64.sTEXT runtime·morestack_noctxt(SB),NOSPLIT,$0 MOVL $0, DX JMP runtime·morestack(SB) 直接跳转到 morestack 函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243TEXT runtime·morestack(SB),NOSPLIT,$0-0&#x2F;&#x2F; Cannot grow scheduler stack (m-&gt;g0). get_tls(CX)&#x2F;&#x2F; BX &#x3D; g，g 表示 main goroutine MOVQ g(CX), BX&#x2F;&#x2F; BX &#x3D; g.m MOVQ g_m(BX), BX&#x2F;&#x2F; SI &#x3D; g.m.g0 MOVQ m_g0(BX), SI CMPQ g(CX), SI JNE 3(PC) CALL runtime·badmorestackg0(SB) INT $3&#x2F;&#x2F; ……………………&#x2F;&#x2F; Set g-&gt;sched to context in f.&#x2F;&#x2F; 将函数的返回地址保存到 AX 寄存器 MOVQ 0(SP), AX &#x2F;&#x2F; f&#39;s PC&#x2F;&#x2F; 将函数的返回地址保存到 g.sched.pc MOVQ AX,(g_sched+gobuf_pc)(SI)&#x2F;&#x2F; g.sched.g &#x3D; g MOVQ SI,(g_sched+gobuf_g)(SI)&#x2F;&#x2F; 取地址操作符，调用 morestack_noctxt 之前的 rsp LEAQ 8(SP), AX &#x2F;&#x2F; f&#39;s SP&#x2F;&#x2F; 将 main 函数的栈顶地址保存到 g.sched.sp MOVQ AX,(g_sched+gobuf_sp)(SI)&#x2F;&#x2F; 将 BP 寄存器保存到 g.sched.bp MOVQ BP,(g_sched+gobuf_bp)(SI)&#x2F;&#x2F; newstack will fill gobuf.ctxt.&#x2F;&#x2F; Call newstack on m-&gt;g0&#39;s stack.&#x2F;&#x2F; BX &#x3D; g.m.g0 MOVQ m_g0(BX), BX&#x2F;&#x2F; 将 g0 保存到本地存储 tls MOVQ BX, g(CX)&#x2F;&#x2F; 把 g0 栈的栈顶寄存器的值恢复到 CPU 的寄存器 SP，达到切换栈的目的，下面这一条指令执行之前，&#x2F;&#x2F; CPU 还是使用的调用此函数的 g 的栈，执行之后 CPU 就开始使用 g0 的栈了 MOVQ (g_sched+gobuf_sp)(BX), SP&#x2F;&#x2F; 准备参数 PUSHQ DX &#x2F;&#x2F; ctxt argument&#x2F;&#x2F; 不返回 CALL runtime·newstack(SB) MOVQ $0,0x1003&#x2F;&#x2F; crash if newstack returns POPQ DX &#x2F;&#x2F; keep balance check happy RET 主要做的工作就是将当前 goroutine，也就是 main goroutine 的和调度相关的信息保存到 g.sched 中，以便在调度到它执行时，可以恢复。 最后，将 g0 的地址保存到 tls 本地存储，并且切到 g0 栈执行之后的代码。继续调用 newstack 函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344func newstack(ctxt unsafe.Pointer) &#123; // thisg = g0 thisg := getg() // …………………… // gp = main goroutine gp := thisg.m.curg // Write ctxt to gp.sched. We do this here instead of in // morestack so it has the necessary write barrier. gp.sched.ctxt = ctxt // …………………… morebuf := thisg.m.morebuf thisg.m.morebuf.pc = 0 thisg.m.morebuf.lr = 0 thisg.m.morebuf.sp = 0 thisg.m.morebuf.g = 0 // 检查 g.stackguard0 是否被设置成抢占标志 preempt := atomic.Loaduintptr(&amp;gp.stackguard0) == stackPreempt if preempt &#123; if thisg.m.locks != 0 || thisg.m.mallocing != 0 || thisg.m.preemptoff != &quot;&quot; || thisg.m.p.ptr().status != _Prunning &#123; // 还原 stackguard0 为正常值，表示我们已经处理过抢占请求了 gp.stackguard0 = gp.stack.lo + _StackGuard // 不抢占，调用 gogo 继续运行当前这个 g，不需要调用 schedule 函数去挑选另一个 goroutine gogo(&amp;gp.sched) // never return &#125; &#125; // …………………… if preempt &#123; if gp == thisg.m.g0 &#123; throw(&quot;runtime: preempt g0&quot;) &#125; if thisg.m.p == 0 &amp;&amp; thisg.m.locks == 0 &#123; throw(&quot;runtime: g is running but p is not&quot;) &#125; // Synchronize with scang. casgstatus(gp, _Grunning, _Gwaiting) // …………………… // Act like goroutine called runtime.Gosched. // 修改为 running，调度起来运行 casgstatus(gp, _Gwaiting, _Grunning) // 调用 gopreempt_m 把 gp 切换出去 gopreempt_m(gp) // never return &#125; // ……………………&#125; 去掉了很多暂时还看不懂的地方，留到后面再研究。只关注有关抢占相关的。第一次判断 preempt 标志是 true 时，检查了 g 的状态，发现不能抢占，例如它所绑定的 P 的状态不是 _Prunning，那就恢复它的 stackguard0 字段，下次就不会走这一套流程了。然后，调用 gogo(&amp;gp.sched) 继续执行当前的 goroutine。 中间又处理了很多判断流程，再次判断 preempt 标志是 true 时，调用 gopreempt_m(gp) 将 gp 切换出去。 123456func gopreempt_m(gp *g)&#123; if trace.enabled &#123; traceGoPreempt() &#125; goschedImpl(gp)&#125; 最终调用 goschedImpl 函数： 1234567891011121314151617func goschedImpl(gp *g) &#123; status := readgstatus(gp) if status&amp;^_Gscan != _Grunning &#123; dumpgstatus(gp) throw(&quot;bad g status&quot;) &#125; // 更改 gp 的状态 casgstatus(gp, _Grunning, _Grunnable) // 解除 m 和 g 的关系 dropg() lock(&amp;sched.lock) // 将 gp 放入全局可运行队列 globrunqput(gp) unlock(&amp;sched.lock) // 进入新一轮的调度循环 schedule()&#125; 将 gp 的状态改为 _Grunnable，放入全局可运行队列，等待下次有 m 来全局队列找工作时才能继续运行，毕竟你已经运行这么长时间了，给别人一点机会嘛。 最后，调用 schedule() 函数进入新一轮的调度循环，会找出一个 goroutine 来运行，永不返回。 这样，关于 sysmon 线程在关于调度这块到底做了啥，我们已经回答完了。总结一下： 抢占处于系统调用的 P，让其他 m 接管它，以运行其他的 goroutine。 将运行时间过长的 goroutine 调度出去，给其他 goroutine 运行的机会。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://sun-moon-star-star.github.io/tags/golang/"}]},{"title":"中国剩余定理","slug":"zhongguoshengyudingli","date":"2021-03-11T17:01:45.000Z","updated":"2021-03-11T17:16:07.439Z","comments":true,"path":"2021/03/12/zhongguoshengyudingli/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/03/12/zhongguoshengyudingli/","excerpt":"","text":"中国剩余定理","categories":[],"tags":[{"name":"data structure","slug":"data-structure","permalink":"https://sun-moon-star-star.github.io/tags/data-structure/"}]},{"title":"hyperloglog","slug":"hyperloglog","date":"2021-03-11T10:00:23.000Z","updated":"2021-03-11T10:11:46.770Z","comments":true,"path":"2021/03/11/hyperloglog/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/03/11/hyperloglog/","excerpt":"","text":"hyperloglog伯努利实验- 如果连续抛了n轮硬币，每轮抛到正面就不抛了，那么抛过最大次数的硬币期望为log2(n) - 如果存在抛过最大次数的硬币为n，那么期望上经历了2^n的轮 hash- 数据集到数据集的映射，一般是数据量比较大的数据到整数的映射 计算出hash值 然后分桶 使用剩余的位数转为二进制未代表抛硬币的正反面，然后可以再转，然后设置最大的次数位 计算结果使用调和平均数算出来再乘以桶数","categories":[],"tags":[{"name":"data structure","slug":"data-structure","permalink":"https://sun-moon-star-star.github.io/tags/data-structure/"}]},{"title":"Direct Io","slug":"directio","date":"2021-02-19T09:13:33.000Z","updated":"2021-02-19T13:14:18.397Z","comments":true,"path":"2021/02/19/directio/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/19/directio/","excerpt":"","text":"Direct Io@https://yarchive.net/comp/linux/o_direct.html@https://blog.csdn.net/AXW2013/article/details/70242228 O_DIRECT，绕过缓冲区高速缓存，直接IO直接IO：Linux允许应用程序在执行磁盘IO时绕过缓冲区高速缓存，从用户空间直接将数据传递到文件或磁盘设备，称为直接IO（direct IO）或者裸IO（raw IO）。 应用场景：数据库系统，其高速缓存和IO优化机制均自成一体，无需内核消耗CPU时间和内存去完成相同的任务。使用直接IO的弊端：可能会大大降低性能，内核对缓冲区告诉缓存做了不少优化，包括：按顺序预读取，在成簇磁盘块上执行IO，允许访问同一文件的多个进程共享高速缓存的缓冲区。 使用方法：在调用open函数打开文件或设备时指定O_DIRECT标志。注意可能发生的不一致性：若一进程以O_DIRECT标志打开某文件，而另一进程以普通（即使用了高速缓存缓冲区）打开同一文件，则由直接IO所读写的数据与缓冲区高速缓存中内容之间不存在一致性，应尽量避免这一场景。 使用直接IO需要遵守的一些限制： 用于传递数据的缓冲区，其内存边界必须对齐为块大小的整数倍 数据传输的开始点，即文件和设备的偏移量，必须是块大小的整数倍 待传递数据的长度必须是块大小的整数倍。不遵守上述任一限制均将导致EINVAL错误。 O_SYNC，以同步方式写入文件功能：强制刷新内核缓冲区到输出文件。这是有必要的，因为为了数据安全，需要确保将数据真正写入磁盘或者磁盘的硬件告诉缓存中。 我们先熟悉一下同步IO相关定义和系统调用。 同步IO数据完整性和同步IO文件完整性同步IO的定义：某一IO操作，要么已成功完成到磁盘的数据传递，要么被诊断为不成功。 SUSv3定义的两种同步IO完成类型: synchronized IO data integrity completion：确保针对文件的一次更新传递了足够的信息（部分文件元数据）到磁盘，以便于之后对数据的获取。 synchronized IO file integrity completion：确保针对文件的一次更新传递了所有的信息（所有文件元数据）到磁盘，即使有些在后续对文件数据的操作并不需要。 用于控制文件IO内核缓冲的系统调用 fsync 作用：fsync()系统调用将使缓冲数据和fd相关的所有元数据都刷新到磁盘上。调用fsync会强制使文件处于Synchronized IO file integrity completion状态。 函数声明：int fsync( int fd); 函数返回值： 0: success, -1: error fdatasync作用：fdatasync()系统调用的作用类似fsync()，只是强制文件处于synchronized IO data integrity compeletion状态。 函数声明：int fdatasync( int fd); 函数返回值： 0: success, -1: error 与fsync的区别：fdatasync()可能会减少磁盘操作的次数，由fsync()调用请求的两次变成一次。例如，修改了文件的数据，而文件大小不变，那么调用fdatasync调用请求只强制进行了数据更新，相比之下，fsync()调用会强制将元数据传递到磁盘上，而元数据和文件数据通常驻留在磁盘的不同区域，更新这些数据需要反复在整个磁盘上执行寻道操作。 sync系统调用作用：sync()系统调用会使包含更新文件信息的所有内核缓冲区（即数据块、指针块、元数据等）刷新到磁盘上。 函数声明：void sync( void ); 细节：若内容发生变化的内核缓冲区在30s内未经显式方式同步到磁盘上，则一条长期运行的内核线程会确保将其刷新到磁盘上。这一做法是为了规避缓冲区与相关磁盘文件内容长期处于不一致状态。 使所有写入同步：O_SYNC 调用open()函数时，如制定O_SYNC标志，则会使所有后续输出同步。 fd = open(pathname, O_WRONLY | O_SYNC); 作用：调用open后，每个write调用会自动将文件数据和元数据刷新到磁盘上，即按照Synchronized IO file integrity completion的要求执行写操作。 有无O_SYNC性能对比 采用O_SYNC标志（或者频繁调用fsync(), fdatasync()或sync()）对性能影响极大。 性能下降的直接表现为运行总用时大为增加：在缓冲区为1字节的情况下，运行时间相差1000多倍。 以O_SYNC标志执行写操作时运行总用时和CPU时间之间的巨大差异（1030 - 98.8），原因是系统在每个缓冲区中将数据向磁盘传递时会把程序阻塞起来。 IO缓冲层次关系先总结一下stdio函数库和 内核采用的缓冲这两级缓冲，然后用图说明两层缓冲机制和各种缓冲类型的控制机制。 首先，通过stdio库将用户数据传递到stdio缓冲区，该缓冲区位于用户态内存区。 当缓冲区填满，stdio库会调用write()系统调用，将数据传递到内核高速缓冲区，该缓冲区位于内核态内存区。 最终，内核发起磁盘操作。","categories":[],"tags":[{"name":"io","slug":"io","permalink":"https://sun-moon-star-star.github.io/tags/io/"}]},{"title":"HTTP 协议","slug":"http","date":"2021-02-19T01:56:54.000Z","updated":"2021-02-19T13:14:11.413Z","comments":true,"path":"2021/02/19/http/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/19/http/","excerpt":"","text":"HTTPHTTP 协议HTTP 是 HyperText Transfer Protocol（超文本传输协议）的缩写，它是互联网上应用最为广泛的一种网络协议，所有 WWW 文件都必须遵守这个标准。 伴随着计算机网络和浏览器的诞生，HTTP 1.0/1.1 也随之而来，它建立在 TCP 协议之上，处于计算机网络中的应用层，所以 HTTP 协议的瓶颈及其优化技巧都是基于 TCP 协议本身的特性，例如 TCP 建立连接的 3 次握手和断开连接的 4 次挥手，以及每次建立连接带来的 RTT 延迟时间等。 HTTP 1.0 与 1.1 的主要区别在于长连接支持、多路复用、带宽节约与数据压缩等，相对于 HTTP/2，本文将其通称为 HTTP/1。 HTTP/1 的缺陷连接无法复用：连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对大量小文件请求影响较大（没有达到最大窗口请求就被终止）。 HTTP/1.0 传输数据时，每次都需要重新建立连接，增加延迟。 HTTP/1.1 虽然加入 keep-alive 可以复用一部分连接，但域名分片等情况下仍然需要建立多个 connection，耗费资源，给服务器带来性能压力。 Head-Of-Line Blocking（HOLB，队头阻塞）：这会导致带宽无法被充分利用，以及后续健康请求被阻塞。HOLB 是指一系列包（package）因为第一个包被阻塞；当页面中需要请求很多资源的时候，HOLB 会导致在达到最大请求数量时，剩余的资源需要等待其它资源请求完成后才能发起请求。 HTTP 1.0：下个请求必须在前一个请求返回后才能发出，request-response对按序发生。显然，如果某个请求长时间没有返回，那么接下来的请求就全部阻塞了。 HTTP 1.1：尝试使用 pipeling 来解决，即浏览器可以一次性发出多个请求（同个域名、同一条 TCP 链接）。但 pipeling 要求返回是按序的，那么前一个请求如果很耗时（比如处理大图片），那么后面的请求即使服务器已经处理完，仍会等待前面的请求处理完才开始按序返回。所以，pipeling 只部分解决了 HOLB。 协议开销大： HTTP/1 在使用时，header 里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求 header 基本不怎么变化，尤其在移动端增加用户流量。 安全因素：HTTP/1 在传输数据时，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份，这在一定程度上无法保证数据的安全性。 HTTP/22015 年，继承于 SPDY 的 HTTP/2 协议发布了。HTTP/2 是 HTTP/1 的替代品，但它不是重写，协议中还保留着第一代的一些内容，比如 HTTP 方法、状态码与语义等都与 HTTP/1 一样。 HTTP/2 基于SPDY3，专注于性能，最大的一个目标是在用户和网站间只用一个连接。 HTTP/2 由两个规范组成： Hypertext Transfer Protocol version 2 - RFC7540 HPACK - Header Compression for HTTP/2 - RFC7541 HTTP/2 特性二进制传输: HTTP/2 采用二进制格式传输数据，而非 HTTP/1 的文本格式，二进制协议解析起来更高效。 HTTP/1 的请求和响应报文，都是由起始行、首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。 接下来我们介绍几个重要的概念： 流（stream）：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N） 消息（message）：指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成 帧（frame）：HTTP/2 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流，承载着特定类型的数据，如 HTTP 首部、负荷等 HTTP/2 中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。 多路复用在 HTTP/2 中引入了多路复用技术。多路复用很好地解决了浏览器限制同一个域名下的请求数量的问题，同时也更容易实现全速传输，毕竟新开一个 TCP 连接都需要慢慢提升传输速度。 在 HTTP/2 中，有了二进制分帧之后，HTTP/2 不再依赖 TCP 链接去实现多流并行了，像前边提到的，在 HTTP/2 中。 同域名下所有通信都在单个连接上完成。 单个连接可以承载任意数量的双向数据流。 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。 这一特性，使性能有了极大提升： 同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应，消除了因多个 TCP 连接而带来的延时和内存消耗 并行交错地发送多个请求，请求之间互不影响 并行交错地发送多个响应，响应之间互不干扰 在 HTTP/2 中，每个请求都可以带一个 31 bit 的优先值，数值越大优先级越低，0 表示最高优先级。有了这个优先值，客户端和服务器就可以在处理不同流时采取不同的策略，以最优的方式发送流、消息和帧。 Header 压缩在 HTTP/1 中，我们使用文本的形式传输 header，在 header 携带 cookie 的情况下，可能每次都需要重复传输几百到几千字节。 为了减少这块的资源消耗并提升性能， HTTP/2 对这些首部采取了压缩策略： HTTP/2 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送 首部表在 HTTP/2 的连接存续期内始终存在，由客户端和服务器共同渐进地更新 每个新的首部键-值对要么被追加到当前表的末尾，要么替换表中之前的值 例如两个请求， 请求 1 发送了所有头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销。 Server PushServer Push 即服务端能通过 push 的方式将客户端需要的内容预先推送过去，也叫“cache push”。 可以想象以下情况：某些资源客户端是一定会请求的，这时就可以采取服务端 push 的技术，提前给客户端推送必要的资源，这样就可以相对减少一点延迟时间。当然在浏览器兼容的情况下你也可以使用 prefetch。 例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 时再发送这些请求。 服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 RST_STREAM 帧来拒收。主动推送也遵守同源策略，换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。 HTTP/3虽然 HTTP/2 解决了很多之前旧版本的问题，但是它还是存在一个巨大的问题，主要是底层支撑的 TCP 协议造成的。 上文提到 HTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP/2 的表现情况反倒不如 HTTP/1 了。 因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。 那么可能就会有人考虑到去修改 TCP 协议，其实这已经是一件不可能完成的任务了，因为 TCP 存在的时间实在太长，已经充斥在各种设备中，并且这个协议是由操作系统实现的，更新起来不大现实。 基于这个原因，Google 就自己架起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上，HTTP/3 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP/3 最大的改造就是使用了 QUIC。 QUIC 虽然基于 UDP，但是在原本的基础上新增了很多功能，接下来我们重点介绍几个 QUIC 功能。 QUIC 功能0RTT通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。0RTT 建连可以说是 QUIC 相比 HTTP/2 最大的性能优势。那什么是 0RTT 建连呢？ 这里面有两层含义: 1、传输层 0RTT 就能建立连接。 2、加密层 0RTT 就能建立加密连接。 因为这里考虑到安全性，我们就拿加了 LTS 的“安全的 HTTP 协议”HTTPS 来对比。HTTPS 的一次完全握手的建连过程，需要 3 个 RTT，就算是会话复用也需要至少 2 个 RTT。 而 QUIC 呢？由于建立在 UDP 的基础上，同时又实现了 0RTT 的安全握手，所以在大部分情况下，只需要 0 个 RTT 就能实现数据发送，在实现前向加密的基础上，并且 0RTT 的成功率相比 TLS 的会话记录单要高很多。 多路复用QUIC 原生实现了多路复用功能，并且传输的单个数据流可以保证有序交付且不会影响其它数据流，这样的技术就解决了前边提到的 TCP 多路复用存在的问题。 同 HTTP/2 一样，同一个 QUIC 连接上可以创建多个 stream 来发送多个 HTTP 请求，但是，QUIC 是基于 UDP 的，因为一个连接上的多个 stream 之间没有依赖，所以不存在 HTTP/2 中的问题。比如下图中 stream2 丢了一个 UDP 包，不会影响后面跟着 Stream3 和 Stream4，不存在 TCP 队头阻塞。虽然 stream2 的那个包需要重新传，但是 stream3、stream4 的包无需等待就可以发给用户。 另外 QUIC 在移动端的表现也会比 TCP 好。因为 TCP 是基于 IP 和端口去识别连接的，这种方式在多变的移动端网络环境下是很脆弱的。而 QUIC 是通过 ID 的方式去识别一个连接，不管你网络环境如何变化，只要 ID 不变，就能迅速重连上。 加密认证的报文TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改、注入和窃听，比如修改序列号与滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。 相比之下，QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。 这样只要是针对 QUIC 报文进行了任何修改，接收端都能够及时发现，有效地降低了安全风险。 Stream Frame 的报文头部，有认证；报文内容，全部经过加密。 前向纠错机制QUIC 协议有一个非常独特的特性，称为前向纠错（Forward Error Correction，FEC），每个数据包除了它本身的内容之外，还包括了部分其它数据包的数据，因此少量的丢包可以通过其它包的冗余数据直接组装而无需重传。 前向纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为丢包导致的数据重传次数。这会取得更好的效果，因为数据重传将会消耗更多的时间，包括确认数据包丢失、请求重传与等待新数据包等步骤。 假如说这次我要发送三个包，那么协议会算出这三个包的异或值并单独发出一个校验包，也就是总共发出了四个包，当出现其中的非校验包丢包的情况时，可以通过另外三个包计算出丢失的数据包的内容。当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了。 总结HTTP/1 有连接无法复用、队头阻塞、协议开销大和安全因素等多个缺陷 HTTP/2 通过多路复用、二进制流与 Header 压缩等技术，极大地提高了性能，但是还是存在一些问题 HTTP/3 抛弃 TCP 协议，以全新的视角重新设计 HTTP。其底层支撑是 QUIC 协议，该协议基于 UDP，有 UDP 特有的优势，同时它又取了 TCP 中的精华，实现了即快又可靠的协议 从 HTTP/1 到 HTTP/3，HTTP 协议经过不断进化，性能越来越高，在这个过程中，底层协议甚至从 TCP 改为了之前被认定为不适合 UDP，这其中不断探索的设计思想值得学习。虽然本文是简单的介绍，但已经把这一演进过程简单地总结了出来，希望读者能够有所收获。","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://sun-moon-star-star.github.io/tags/http/"}]},{"title":"面试","slug":"questions","date":"2021-02-19T01:56:54.000Z","updated":"2021-02-19T13:13:35.224Z","comments":true,"path":"2021/02/19/questions/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/19/questions/","excerpt":"","text":"面试 在文件系统中，也有类似的缓存。如果不想使用任何缓存，应该怎么做？如果调用mmap，使用了多少缓存？如果调用系统调用open + read，使用了多少缓存？如果调用fopen + fread，又使用了多少缓存？ 管理节点通过udp心跳的方式感知数据节点是否可用，而计算节点通过tcp长链接的方式和数据节点交互。二者看到的状态是否存在不一致？如果是，你会如何解决？","categories":[],"tags":[{"name":"interview","slug":"interview","permalink":"https://sun-moon-star-star.github.io/tags/interview/"}]},{"title":"tips","slug":"tips","date":"2021-02-11T08:32:24.000Z","updated":"2021-02-19T13:13:51.363Z","comments":true,"path":"2021/02/11/tips/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/11/tips/","excerpt":"","text":"backend压缩 减少javascript,css,html内容本身的大小: 删除多余的空格、注释、tab等 压缩: 压缩的开销远小于传输的开销，带宽比较贵 抽象 不要过于抽象以至于代码难以阅读 正则表达式 时间开销大 难以阅读， 难度大 适合原子的功能，不适合做过于复杂的判断 微服务 细分的时候要注意体系和理解性","categories":[],"tags":[{"name":"tips","slug":"tips","permalink":"https://sun-moon-star-star.github.io/tags/tips/"}]},{"title":"流量录制和回放","slug":"liuliangluzhihehuifang","date":"2021-02-10T07:35:34.000Z","updated":"2021-02-19T13:14:06.578Z","comments":true,"path":"2021/02/10/liuliangluzhihehuifang/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/10/liuliangluzhihehuifang/","excerpt":"","text":"功能将线上的真实请求流量录制下来，包含调用下游服务的流量。 拦截点选择流量录制必然要在某个点上对流量进行拦截并镜像，常见的拦截方式如下： 业务代码 rpc框架 语言标准库 libc syscall tcp/ip协议栈 网卡驱动 分析: 为了做到尽量无业务浸入、具体框架无关，业务代码和rpc框架拦截方式不适合。 syscal拦截成本高，到tcp/ip协议栈的时候线程等信息丢失更不容易区分，所以后面几种方式都不适合。 综上，比较适合拦截的方式是libc、语言标准库。 对于底层使用libc的语言，如php，可以在libc进行拦截。 对于没有使用libc的语言，如golang，可以在语言标准库上修改做拦截。 链路追踪流量录制不仅要录制接口inbound请求流量，还要录制下游outbound请求流量，那如何将inbound请求和outbound请求关联起来呢？ 利用分布式追踪原理，用唯一的traceID将请求关联起来。 对于http服务，每个请求会单独开一个goroutine处理，对于大部分的场景都是在一个goroutine完成。可以使用goroutineID来关联inbound和outbound请求，对于大部分场景都适用。 对于少数并发等不在一个goroutine处理的请求，就需要传同一个id来标识，需要少量业务代码改动。 流量存储 方便ES检索 二进制安全，数据不丢失 流量回放流量回放的前提是基于录制的流量进行操作。 如果录制的流量只有Inbound请求，没有Outbound请求，那么，回放过程非常简单。只需构造http请求发给SUT，等待SUT返回Response后进行对比即可。 但实际业务中，不仅会有Outbound请求，而且Outbound请求还很多，协议也各种各样。 因此，流量回放首要解决的问题有： 如何拦截SUT的Outbound请求，将其转发给Agent的Mock Server。 如何在录制的流量里，选择最合适的Outbound返回给SUT。 @https://github.com/didi/sharingan/wiki","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://sun-moon-star-star.github.io/tags/test/"}]},{"title":"墨子·修身","slug":"mozi-xiushen","date":"2021-02-10T03:51:20.000Z","updated":"2021-02-19T13:13:41.096Z","comments":true,"path":"2021/02/10/mozi-xiushen/","link":"","permalink":"https://sun-moon-star-star.github.io/2021/02/10/mozi-xiushen/","excerpt":"","text":"墨子·修身 君子战虽有陈，而勇为本焉。丧虽有礼，而哀为本焉。士虽有学，而行为本焉。是故置本不安者，无务丰末。近者不亲，无务来远。亲戚不附，无务外交。事无终始，无务多业。举物而暗，无务博闻。 君子作战虽用阵势，但必以勇敢为本；办丧事虽讲礼仪，但必以哀痛为本；做官虽讲才识，但必以德行为本。所以立本不牢的，就不必讲究枝节的繁盛；身边的人不能亲近，就不必讲究招徕远方之民；亲戚不能使之归附，就不必讲究结纳外人；做一件事情有始无终，就不必谈起从事多种事业；举一件事物尚且弄不明白，就不必追求广见博闻。 是故先王之治天下也，必察迩来远，君子察迩而迩修者也。见不修行，见毁，而反之身者也，此以怨省而行修矣。谮慝之言，无入之耳，批捍之声，无出之口，杀伤人之孩，无存之心，虽有诋讦之民，无所依矣。 所以先王治理天下，必定要明察左右而招徕远人。君子能明察左右，左右之人也就能修养自己的品行了。君子不能修养自己的品行而受人诋毁，那就应当自我反省，因而怨少而品德日修。谗害诽谤之言不入于耳，攻击他人之语不出于口，伤害人的念头不存于心，这样，即使遇有好诋毁、攻击的人，也就无从施展了。 故君子力事日强，愿欲日逾，设壮日盛。君子之道也，贫则见廉，富则见义，生则见爱，死则见哀。四行者不可虚假，反之身者也。藏于心者，无以竭爱。动于身者，无以竭恭。出于口者，无以竭驯。畅之四支，接之肌肤，华发隳颠，而犹弗舍者，其唯圣人乎！ 所以君子本身的力量一天比一天加强，志向一无比一天远大，庄敬的品行一天比一天完善。君子之道（应包括如下方面）：贫穷时表现出廉洁，富足时表现出恩义，对生者表示出慈爱，对死者表示出哀痛。这四种品行不是可以装出来的，而是必须自身具备的。凡是存在于内心的，是无穷的慈爱；举止于身体的，是无比的谦恭；谈说于嘴上的，是无比的雅驯。（让上述四种品行）畅达于四肢和肌肤，直到白发秃顶之时仍不肯舍弃，大概只有圣人吧！ 志不强者智不达，言不信者行不果。据财不能以分人者，不足与友。守道不笃，偏物不博，辩是非不察者，不足与游。本不固者末必几，雄而不修者，其后必惰，原浊者流不清，行不信者名必秏。名不徒生而誉不自长，功成名遂，名誉不可虚假，反之身者也。务言而缓行，虽辩必不听。多力而伐功，虽劳必不图。慧者心辩而不繁说，多力而不伐功，此以名誉扬天下。言无务为多而务为智，无务为文而务为察。故彼智无察，在身而情，反其路者也。善无主于心者不留，行莫辩于身者不立。名不可简而成也，誉不可巧而立也，君子以身戴行者也。思利寻焉，忘名忽焉，可以为士于天下者，未尝有也。 意志不坚强的，智慧一定不高；说话不讲信用的，行动一定不果敢；拥有财富而不肯分给人的，不值得和他交友；守道不坚定，阅历事物不广博，辨别是非不清楚的，不值得和他交游。根本不牢的，枝节必危。光勇敢而不注重品行修养的，后必懒惰。源头浊的流不清，行为无信的人名声必受损害，声誉不会无故产生和自己增长。功成了必然名就，名誉不可虚假，必须反求诸己。专说而行动迟缓，虽然会说，但没人听信。出力多而自夸功劳，虽劳苦而不可取。聪明人心里明白而不多说，努力作事而不夸说自己的功劳，因此名誉扬于天下。说话不图繁多而讲究富有智慧，不图文采而讲究明白。所以既无智慧又不能审察，加上自身又懒惰，则必背离正道而行了。善不从本心生出就不能保留，行不由本身审辨就不能树立，名望不会由茍简而成，声誉不会因诈伪而立，君子是言行合一的。以图利为重，忽视立名，（这样）而可以成为天下贤士的人，还不曾有过。 @https://ctext.org/mozi/self-cultivation/zhs","categories":[],"tags":[{"name":"read","slug":"read","permalink":"https://sun-moon-star-star.github.io/tags/read/"}]}],"categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://sun-moon-star-star.github.io/tags/golang/"},{"name":"data structure","slug":"data-structure","permalink":"https://sun-moon-star-star.github.io/tags/data-structure/"},{"name":"io","slug":"io","permalink":"https://sun-moon-star-star.github.io/tags/io/"},{"name":"http","slug":"http","permalink":"https://sun-moon-star-star.github.io/tags/http/"},{"name":"interview","slug":"interview","permalink":"https://sun-moon-star-star.github.io/tags/interview/"},{"name":"tips","slug":"tips","permalink":"https://sun-moon-star-star.github.io/tags/tips/"},{"name":"test","slug":"test","permalink":"https://sun-moon-star-star.github.io/tags/test/"},{"name":"read","slug":"read","permalink":"https://sun-moon-star-star.github.io/tags/read/"}]}